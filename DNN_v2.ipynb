{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks Laboration\n",
    "\n",
    "Data used in this laboration are from the Kitsune Network Attack Dataset, https://archive.ics.uci.edu/ml/datasets/Kitsune+Network+Attack+Dataset . We will focus on the 'Mirai' part of the dataset. Your task is to make a DNN that can classify if each attack is benign or malicious. The dataset has 116 covariates, but to make it a bit more difficult we will remove the first 24 covariates.\n",
    "\n",
    "You need to answer all questions in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Get the data\n",
    "\n",
    "Use `wget` in the terminal of your cloud machine (in the same directory as where you have saved this notebook) to download the data, i.e.\n",
    "\n",
    "wget https://archive.ics.uci.edu/ml/machine-learning-databases/00516/mirai/Mirai_dataset.csv.gz\n",
    "\n",
    "wget https://archive.ics.uci.edu/ml/machine-learning-databases/00516/mirai/Mirai_labels.csv.gz\n",
    "\n",
    "Then unpack the files using `gunzip` in the terminal, i.e.\n",
    "\n",
    "gunzip Mirai_dataset.csv.gz\n",
    "\n",
    "gunzip Mirai_labels.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Get a graphics card\n",
    "\n",
    "Lets make sure that our script can see the graphics card that will be used. The graphics cards will perform all the time consuming calculations in every training iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# Ignore FutureWarning from numpy\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";\n",
    "\n",
    "# Allow growth of GPU memory, otherwise it will always look like all the memory is being used\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Hardware\n",
    "\n",
    "In deep learning, the computer hardware is very important. You should always know what kind of hardware you are working on.\n",
    "\n",
    "Question 1: What graphics card is available in the cloud machine? Run 'nvidia-smi' in the terminal. \n",
    "\n",
    "Question 2: Google the name of the graphics card, how many CUDA cores does it have?\n",
    "\n",
    "Question 3: How much memory does the graphics card have?\n",
    "\n",
    "Question 4: What is stored in the GPU memory while training a DNN ?\n",
    "\n",
    "Question 5: What CPU is available in the cloud machine? How many cores does it have? Run 'lscpu' in the terminal.\n",
    "\n",
    "Question 6: How much CPU memory (RAM) is available in the cloud machine? Run 'free -g' in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1. Tesla K80\n",
    "\n",
    "# Answer 2. 4,992 CUDA cores \n",
    "\n",
    "# Answer 3. According to google the memory on the graphics card is 24 GB\n",
    "# GDDR5 but on the terminal the memory available to us is 11441 MB (approx 12 GB)\n",
    "\n",
    "# Answer 4. Training data, weights of the network, outputs/filter responses for each layer\n",
    "# and gradients of all parameters are stored in GPU memory when training a DNN. This might \n",
    "# be done in batches when all this data cannot be stored together in the GPU.\n",
    "\n",
    "# Answer 5. The CPU available on the cloud machine is Intel(R) Xeon(R) CPU E5-2690 v3. Each \n",
    "# CPU has 6 cores.\n",
    "\n",
    "# Answer 6. Theres a total of 55 GB RAM on the cloud machine out of which 53 GB is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Load the data\n",
    "\n",
    "Load the dataset from the csv files, it will take some time since it is almost 1.4 GB. \n",
    "\n",
    "We will use the function `genfromtxt` to load the data.\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html\n",
    "\n",
    "Load the data from csv files the first time, then save the data as numpy files for faster loading the next time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The covariates have size (764137, 92).\n",
      "The labels have size (764137,).\n",
      "Class 0.0  has count  121621 and class 1.0  has count 642516\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "\n",
    "X = genfromtxt('Mirai_dataset.csv', delimiter=',')\n",
    "Y = genfromtxt('Mirai_labels.csv', delimiter=',')\n",
    "# Load data from file\n",
    "# X = covariates, Y = labels\n",
    "\n",
    "\n",
    "\n",
    "# Save data as numpy arrays, for faster loading in future calls to this cell\n",
    "np.save('Mirai_data.npy', X)\n",
    "np.save('Mirai_labels.npy', Y)\n",
    "\n",
    "# Load data from numpy arrays, for faster loading\n",
    "X = np.load('Mirai_data.npy')\n",
    "Y = np.load('Mirai_labels.npy')\n",
    "\n",
    "\n",
    "\n",
    "# Remove the first 24 covariates\n",
    "X = np.delete(X,range(24),axis=1)\n",
    "\n",
    "print('The covariates have size {}.'.format(X.shape))\n",
    "print('The labels have size {}.'.format(Y.shape))\n",
    "\n",
    "\n",
    "\n",
    "# Print the number of examples of each class\n",
    "a,b = np.unique(Y, return_counts=True)\n",
    "print(\"Class\", a[0],\" has count \", b[0], 'and class', a[1], ' has count', b[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: How good is a naive classifier?\n",
    "\n",
    "Question 7: Given the distribution of examples, how high classification performance can a naive classifier obtain? The naive classifier will assume that all examples belong to one class. Note: you do not need to make a naive classifier, this is a theoretical question, just to understand how good performance we can obtain by random chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs in the labels is 0\n",
      "Number of NaNs in covariates is 0\n"
     ]
    }
   ],
   "source": [
    "# It is common to have NaNs in the data, lets check for it. Hint: np.isnan()\n",
    "#sum(np.isnan(X))\n",
    "a = np.count_nonzero(np.isnan(Y))\n",
    "# Print the number of NaNs (not a number) in the labels\n",
    "print('Number of NaNs in the labels is',a)\n",
    "\n",
    "b = np.count_nonzero(np.isnan(X))\n",
    "# Print the number of NaNs in the covariates\n",
    "print('Number of NaNs in covariates is',b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Preprocessing\n",
    "\n",
    "Lets do some simple preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of covariates is -2.565209060450084e-17 and standard deviation is 0.9999999999999979\n"
     ]
    }
   ],
   "source": [
    "# Convert covariates to floats\n",
    "X = X.astype(float)\n",
    "\n",
    "# Convert labels to ints\n",
    "Y = Y.astype(int)\n",
    "\n",
    "# Remove mean of each covariate (column)\n",
    "for i in range(X.shape[1]):\n",
    "    X[:,i] = X[:,i] - np.mean(X[:,i])\n",
    "    X[:,i] = X[:,i] / np.std(X[:,i])\n",
    "\n",
    "# Divide each covariate (column) by its standard deviation\n",
    "\n",
    "\n",
    "# Check that mean is 0 and standard deviation is 1 for all covariates, by printing mean and std\n",
    "print('Mean of covariates is',np.mean(X), 'and standard deviation is', np.std(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7: Split the dataset\n",
    "\n",
    "Use the first 70% of the dataset for training, leave the other 30% for validation and test, call the variables\n",
    "\n",
    "Xtrain (70%)\n",
    "\n",
    "Xtemp  (30%)\n",
    "\n",
    "Ytrain (70%)\n",
    "\n",
    "Ytemp  (30%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain has size (534896, 92).\n",
      "Ytrain has size (534896,).\n",
      "Xtemp has size (229241, 92).\n",
      "Ytemp has size (229241,).\n",
      "For Ytrain, Class 0  has count  121621 and class 1  has count 413275\n",
      "For Ytemp, only Class 1  has count  229241\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "Xtrain = X[:534896]\n",
    "Xtemp = X[534896:]\n",
    "Ytrain = Y[:534896]\n",
    "Ytemp = Y[534896:]\n",
    "\n",
    "print('Xtrain has size {}.'.format(Xtrain.shape))\n",
    "print('Ytrain has size {}.'.format(Ytrain.shape))\n",
    "\n",
    "print('Xtemp has size {}.'.format(Xtemp.shape))\n",
    "print('Ytemp has size {}.'.format(Ytemp.shape))\n",
    "\n",
    "# Print the number of examples of each class, for the training data and the remaining 30%\n",
    "a,b = np.unique(Ytrain, return_counts=True)\n",
    "print(\"For Ytrain, Class\", a[0],\" has count \", b[0], 'and class', a[1], ' has count', b[1])\n",
    "\n",
    "c,d = np.unique(Ytemp, return_counts=True)\n",
    "print(\"For Ytemp, only Class\", c[0],\" has count \", d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534896"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#70*len(Y)/100\n",
    "len(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8: Number of examples per class\n",
    "\n",
    "Question 8: Can we use the dataset as it is? Why not?\n",
    "\n",
    "Lets randomly shuffle the data, to get some examples of each class in training data and in the remaining 30%. Use the function `shuffle` in scikit learn\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Ytrain, Class 0  has count  85121 and class 1  has count 449775\n",
      "For Ytemp, Class 0  has count  36500 and class 1  has count 192741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Randomly shuffle data, to get both classes in training and testing\n",
    "id = shuffle(range(764137))\n",
    "X_shuffle = X[id]\n",
    "Y_shuffle = Y[id]\n",
    "# Divide the data into training and validation/test again\n",
    "Xtrain = X_shuffle[:534896,:]\n",
    "Xtemp = X_shuffle[534896:,:]\n",
    "Ytrain = Y_shuffle[:534896]\n",
    "Ytemp = Y_shuffle[534896:]\n",
    "\n",
    "\n",
    "# Print the number of examples of each class, for the training data and the remaining 30%\n",
    "\n",
    "a,b = np.unique(Ytrain, return_counts=True)\n",
    "print(\"For Ytrain, Class\", a[0],\" has count \", b[0], 'and class', a[1], ' has count', b[1])\n",
    "\n",
    "c,d = np.unique(Ytemp, return_counts=True)\n",
    "print(\"For Ytemp, Class\", c[0],\" has count \", d[0], 'and class', c[1], ' has count', d[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Part 9: Split non-training data data into validation and test\n",
    "Split your non-training data (Xtemp, Ytemp) into 50% validation (Xval, Yval) and 50% testing (Xtest, Ytest), we use a function from scikit learn. \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation and test data have size (114620, 92), (114621, 92), (114620,) and (114621,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xval, Xtest, Yval, Ytest = train_test_split(Xtemp, Ytemp, test_size=0.5)\n",
    "\n",
    "\n",
    "print('The validation and test data have size {}, {}, {} and {}'.format(Xval.shape, Xtest.shape, Yval.shape, Ytest.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 10: DNN classification\n",
    "\n",
    "Finish this code to create a first version of the classifier using a DNN. Start with a simple network with 2 dense layers (with 20 nodes each), using sigmoid activation functions. The final dense layer should have a single node and a sigmoid activation function. We start with the SGD optimizer.\n",
    "\n",
    "Relevant functions are\n",
    "\n",
    "`model.add()`, adds a layer to the network\n",
    "\n",
    "`Dense()`, a dense network layer\n",
    "\n",
    "`model.compile()`, compile the model, add \" metrics=['accuracy'] \" to print the classification accuracy during the training\n",
    "\n",
    "`model.fit()`, train the model with some training data\n",
    "\n",
    "`model.evaluate()`, apply the trained model to some test data\n",
    "\n",
    "See https://keras.io/layers/core/ for information on how the `Dense()` function works\n",
    "\n",
    "Import a relevant cost / loss function for binary classification from keras.losses (https://keras.io/losses/)\n",
    "\n",
    "See https://keras.io/models/model/ for how to compile, train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "# Set seed from random number generator, for better comparisons\n",
    "from numpy.random import seed\n",
    "seed(123)\n",
    "\n",
    "def build_DNN(input_shape, n_layers, n_nodes, act_fun='sigmoid', optimizer='sgd', learning_rate=0.01, \n",
    "              use_bn=False, use_dropout=False, use_custom_dropout=False):\n",
    "    \n",
    "    # Setup optimizer, depending on input parameter string\n",
    "    if optimizer == 'sgd':\n",
    "        optim_setup = SGD(lr=learning_rate)\n",
    "    if optimizer == 'adam':\n",
    "        optim_setup = Adam(lr=learning_rate)\n",
    "\n",
    "    # Setup a sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add layers to the model, using the input parameters of the build_DNN function\n",
    "    # Add first layer, requires input shape\n",
    "    model.add(Dense(n_nodes, activation=act_fun, input_shape=input_shape))\n",
    "    \n",
    "    if use_bn == True:\n",
    "        model.add(BatchNormalization())\n",
    "    if use_dropout == True:\n",
    "        model.add(Dropout(0.5))\n",
    "    if use_custom_dropout == True:\n",
    "        model.add(myDropout(rate = 0.5, seed = 123))\n",
    "\n",
    "    # Add remaining layers, do not require input shape\n",
    "    for i in range(n_layers-1):\n",
    "        model.add(Dense(n_nodes, activation=act_fun))\n",
    "        if use_bn == True:\n",
    "            model.add(BatchNormalization())\n",
    "        if use_dropout == True:\n",
    "            model.add(Dropout(0.5))\n",
    "        if use_custom_dropout == True:\n",
    "            model.add(myDropout(rate = 0.5, seed = 123))\n",
    "    \n",
    "    # Final layer\n",
    "    if act_fun == 'relu':\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "    else:\n",
    "        model.add(Dense(1, activation=act_fun))\n",
    "    \n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optim_setup, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define a help function for plotting the training results\n",
    "\n",
    "# IMPORTANT NOTE\n",
    "# The history unfortunately behaves a bit randomly for every user\n",
    "# If the plots for accuracy and loss look mixed, change the order of\n",
    "# val_loss, val_acc, loss, acc\n",
    "# until the plots look as they \"should\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_results(history):\n",
    "    val_loss, val_acc, loss, acc = history.history.values()\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(val_loss)\n",
    "    plt.plot(val_acc)\n",
    "  \n",
    "    plt.legend(['Training','Validation'])\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(loss)\n",
    "    plt.plot(acc)\n",
    "    plt.legend(['Training','Validation'])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 11: Train the DNN\n",
    "\n",
    "Time to train the DNN, we start simple with 2 layers with 2 nodes each, learning rate 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 layers, 20 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534896 samples, validate on 114620 samples\n",
      "Epoch 1/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.4188 - accuracy: 0.8409 - val_loss: 0.3858 - val_accuracy: 0.8420\n",
      "Epoch 2/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.3625 - accuracy: 0.8409 - val_loss: 0.3334 - val_accuracy: 0.8420\n",
      "Epoch 3/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.3080 - accuracy: 0.8409 - val_loss: 0.2801 - val_accuracy: 0.8420\n",
      "Epoch 4/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.2602 - accuracy: 0.8424 - val_loss: 0.2405 - val_accuracy: 0.8523\n",
      "Epoch 5/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.2286 - accuracy: 0.8619 - val_loss: 0.2171 - val_accuracy: 0.8794\n",
      "Epoch 6/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.2107 - accuracy: 0.8899 - val_loss: 0.2041 - val_accuracy: 0.9029\n",
      "Epoch 7/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.2004 - accuracy: 0.9040 - val_loss: 0.1963 - val_accuracy: 0.9042\n",
      "Epoch 8/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.1941 - accuracy: 0.9044 - val_loss: 0.1911 - val_accuracy: 0.9050\n",
      "Epoch 9/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.1897 - accuracy: 0.9050 - val_loss: 0.1874 - val_accuracy: 0.9055\n",
      "Epoch 10/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.1864 - accuracy: 0.9057 - val_loss: 0.1845 - val_accuracy: 0.9063\n",
      "Epoch 11/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.1838 - accuracy: 0.9064 - val_loss: 0.1822 - val_accuracy: 0.9070\n",
      "Epoch 12/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.1817 - accuracy: 0.9068 - val_loss: 0.1802 - val_accuracy: 0.9073\n",
      "Epoch 13/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.1799 - accuracy: 0.9072 - val_loss: 0.1785 - val_accuracy: 0.9078\n",
      "Epoch 14/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.1783 - accuracy: 0.9075 - val_loss: 0.1771 - val_accuracy: 0.9081\n",
      "Epoch 15/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.1769 - accuracy: 0.9079 - val_loss: 0.1758 - val_accuracy: 0.9083\n",
      "Epoch 16/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.1757 - accuracy: 0.9081 - val_loss: 0.1746 - val_accuracy: 0.9086\n",
      "Epoch 17/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.1746 - accuracy: 0.9084 - val_loss: 0.1736 - val_accuracy: 0.9088\n",
      "Epoch 18/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.1736 - accuracy: 0.9088 - val_loss: 0.1726 - val_accuracy: 0.9091\n",
      "Epoch 19/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.1727 - accuracy: 0.9090 - val_loss: 0.1718 - val_accuracy: 0.9094\n",
      "Epoch 20/20\n",
      "534896/534896 [==============================] - 1s 1us/step - loss: 0.1719 - accuracy: 0.9092 - val_loss: 0.1710 - val_accuracy: 0.9095\n"
     ]
    }
   ],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "n_nodes = 20\n",
    "n_layers = 2\n",
    "\n",
    "input_shape = Xtrain.shape[1:]\n",
    "\n",
    "# Build the model\n",
    "model1 = build_DNN(input_shape, n_layers, n_nodes, learning_rate = 0.1)\n",
    "\n",
    "# Train the model, provide training data and validation data\n",
    "history1 = model1.fit(Xtrain, Ytrain, batch_size = batch_size, epochs = epochs, validation_data = (Xval, Yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114621/114621 [==============================] - 4s 35us/step\n",
      "Test loss: 0.1729\n",
      "Test accuracy: 0.9077\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "score = model1.evaluate(Xtest, Ytest)\n",
    "\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 12: More questions\n",
    "\n",
    "Question 9: What happens if you add several Dense layers without specifying the activation function?\n",
    "\n",
    "Question 10: How are the weights in each dense layer initialized as default? How are the bias weights initialized?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 9:\n",
    "# If nothing is specified, no activation is applied --> linear activation a(x) = x\n",
    "# Even with several Dense layers this won't change and the model will do linear regression\n",
    "\n",
    "# Answer 10:\n",
    "# The default kernel initializer is glorot_uniform (Glorot uniform initializer) and the bias initializer is zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 13: Balancing the classes\n",
    "\n",
    "This dataset is rather unbalanced, we need to define class weights so that the training pays more attention to the class with fewer samples. We use a function in scikit learn\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.14197437 0.5946262 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(Ytrain),Ytrain)\n",
    "\n",
    "# Print the class weights\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 layers, 20 nodes, class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534896 samples, validate on 114620 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.5220 - accuracy: 0.8409 - val_loss: 0.4661 - val_accuracy: 0.8420\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4468 - accuracy: 0.8409 - val_loss: 0.4309 - val_accuracy: 0.8420\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4252 - accuracy: 0.8409 - val_loss: 0.4179 - val_accuracy: 0.8420\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4158 - accuracy: 0.8409 - val_loss: 0.4108 - val_accuracy: 0.8420\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4099 - accuracy: 0.8409 - val_loss: 0.4056 - val_accuracy: 0.8420\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4050 - accuracy: 0.8409 - val_loss: 0.4009 - val_accuracy: 0.8420\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4005 - accuracy: 0.8409 - val_loss: 0.3964 - val_accuracy: 0.8420\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.3960 - accuracy: 0.8409 - val_loss: 0.3920 - val_accuracy: 0.8420\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-3493b59a9566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_DNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhistory2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3732\u001b[0m               'You must feed a value for placeholder %s' % (tensor,))\n\u001b[1;32m   3733\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3734\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3735\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3736\u001b[0m         \u001b[0;31m# Temporary workaround due to `convert_to_tensor` not casting floats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1182\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1183\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1184\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 10000 #10000\n",
    "epochs = 20 #20\n",
    "n_layers = 2\n",
    "input_shape = Xtrain.shape[1:]\n",
    "n_nodes = 20\n",
    "\n",
    "# Build and train model\n",
    "model2 = build_DNN(input_shape, n_layers, n_nodes)\n",
    "\n",
    "history2 = model2.fit(Xtrain, Ytrain, batch_size = batch_size, epochs = epochs, verbose = 2, validation_data = (Xval, Yval), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114621/114621 [==============================] - 0s 1us/step\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 20)                1860      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 2,301\n",
      "Trainable params: 2,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.3942\n",
      "Test accuracy: 0.8397\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test data\n",
    "score = model2.evaluate(Xtest, Ytest, batch_size = batch_size)\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 14: More questions\n",
    "\n",
    "Question 11: Why do we have to use a batch size? Why can't we simply use all data at once? This is more relevant for even larger datasets.\n",
    "\n",
    "Question 12: How busy is the GPU for a batch size of 100? How much GPU memory is used? Hint: run 'nvidia-smi' on the cloud computer a few times during training.\n",
    "\n",
    "Question 13: What is the processing time for one training epoch when the batch size is 100? What is the processing time for one epoch when the batch size is 1,000? What is the processing time for one epoch when the batch size is 10,000? Explain the results. \n",
    "\n",
    "Question 14: How many times are the weights in the DNN updated in each training epoch if the batch size is 100? How many times are the weights in the DNN updated in each training epoch if the batch size is 1,000? How many times are the weights in the DNN updated in each training epoch if the batch size is 10,000?  \n",
    "\n",
    "Question 15: What limits how large the batch size can be?\n",
    "\n",
    "Question 16: Generally speaking, how is the learning rate related to the batch size? If the batch size is decreased, how should the learning rate be changed?\n",
    "\n",
    "Lets use a batch size of 10,000 from now on, and a learning rate of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 11:\n",
    "# We have to use a batch size because all the data wouldn't fit in the storage space of the GPU all at once.\n",
    "# Answer 12:\n",
    "# With batch size = 100 between 29 and 32% GPU memory is being used.\n",
    "# Answer 13:\n",
    "# Processing time for:\n",
    "# 1 training epoch with batch size = 100: 13 sec\n",
    "# 1 training epoch with batch size = 1000: 2 sec\n",
    "# 1 training epoch with batch size = 10000: 1 sec\n",
    "# Explanation:\n",
    "# Answer 14:\n",
    "# Number of times weights are updated for:\n",
    "# Batch size 100: 534896/100\n",
    "# Batch size 1000: 534896/1000\n",
    "# Batch size 10000: 534896/10000\n",
    "\n",
    "\n",
    "# Answer 15:\n",
    "# The batch size shouldn't be to small because this makes the gradien more noisy (but can have regularization effect). The batch size cannot be larger than the memory capacity of the GPU after accounting for all the other data that is stored on GPU memory.\n",
    "\n",
    "# Answer 16:\n",
    "# The larger the batch size, the higher the learning rate should be because you don't update the weights as often relative to smaller batch sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 15: Increasing the complexity\n",
    "\n",
    "Lets try some different configurations of number of layers and number of nodes per layer.\n",
    "\n",
    "Question 17: How many trainable parameters does the network with 4 dense layers with 50 nodes each have, compared to the initial network with 2 layers and 20 nodes per layer? Hint: use model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The initial network has 2,301 Trainable params\n",
    "#The network with 4 layers and 50 nodes has 12,351 Trainable params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 layers, 20 nodes, class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534896 samples, validate on 114620 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.5248 - accuracy: 0.8409 - val_loss: 0.4787 - val_accuracy: 0.8420\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4630 - accuracy: 0.8409 - val_loss: 0.4500 - val_accuracy: 0.8420\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4464 - accuracy: 0.8409 - val_loss: 0.4412 - val_accuracy: 0.8420\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4412 - accuracy: 0.8409 - val_loss: 0.4382 - val_accuracy: 0.8420\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4394 - accuracy: 0.8409 - val_loss: 0.4371 - val_accuracy: 0.8420\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4387 - accuracy: 0.8409 - val_loss: 0.4366 - val_accuracy: 0.8420\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4384 - accuracy: 0.8409 - val_loss: 0.4364 - val_accuracy: 0.8420\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.4383 - accuracy: 0.8409 - val_loss: 0.4364 - val_accuracy: 0.8420\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.4382 - accuracy: 0.8409 - val_loss: 0.4363 - val_accuracy: 0.8420\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.4382 - accuracy: 0.8409 - val_loss: 0.4363 - val_accuracy: 0.8420\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.4382 - accuracy: 0.8409 - val_loss: 0.4362 - val_accuracy: 0.8420\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.4381 - accuracy: 0.8409 - val_loss: 0.4362 - val_accuracy: 0.8420\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.4381 - accuracy: 0.8409 - val_loss: 0.4362 - val_accuracy: 0.8420\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.4381 - accuracy: 0.8409 - val_loss: 0.4361 - val_accuracy: 0.8420\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.4381 - accuracy: 0.8409 - val_loss: 0.4361 - val_accuracy: 0.8420\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.4380 - accuracy: 0.8409 - val_loss: 0.4361 - val_accuracy: 0.8420\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.4380 - accuracy: 0.8409 - val_loss: 0.4361 - val_accuracy: 0.8420\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.4380 - accuracy: 0.8409 - val_loss: 0.4360 - val_accuracy: 0.8420\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.4380 - accuracy: 0.8409 - val_loss: 0.4360 - val_accuracy: 0.8420\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.4379 - accuracy: 0.8409 - val_loss: 0.4360 - val_accuracy: 0.8420\n"
     ]
    }
   ],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "input_shape = Xtrain.shape[1:]\n",
    "n_layers = 4\n",
    "n_nodes = 20\n",
    "\n",
    "# Build and train model\n",
    "model3 = build_DNN(input_shape, n_layers, n_nodes)\n",
    "\n",
    "history3 = model3.fit(Xtrain, Ytrain, batch_size = batch_size, epochs = epochs, verbose = 2, validation_data = (Xval, Yval), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114621/114621 [==============================] - 0s 1us/step\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 20)                1860      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 3,141\n",
      "Trainable params: 3,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.4399\n",
      "Test accuracy: 0.8397\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test data\n",
    "score = model3.evaluate(Xtest, Ytest, batch_size = batch_size)\n",
    "\n",
    "model3. summary()\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 layers, 50 nodes, class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534896 samples, validate on 114620 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.5260 - accuracy: 0.8146 - val_loss: 0.4514 - val_accuracy: 0.8420\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4421 - accuracy: 0.8409 - val_loss: 0.4335 - val_accuracy: 0.8420\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4316 - accuracy: 0.8409 - val_loss: 0.4263 - val_accuracy: 0.8420\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4251 - accuracy: 0.8409 - val_loss: 0.4201 - val_accuracy: 0.8420\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4189 - accuracy: 0.8409 - val_loss: 0.4139 - val_accuracy: 0.8420\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4127 - accuracy: 0.8409 - val_loss: 0.4077 - val_accuracy: 0.8420\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4064 - accuracy: 0.8409 - val_loss: 0.4015 - val_accuracy: 0.8420\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.4001 - accuracy: 0.8409 - val_loss: 0.3951 - val_accuracy: 0.8420\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.3936 - accuracy: 0.8409 - val_loss: 0.3886 - val_accuracy: 0.8420\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.3870 - accuracy: 0.8409 - val_loss: 0.3819 - val_accuracy: 0.8420\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.3802 - accuracy: 0.8409 - val_loss: 0.3751 - val_accuracy: 0.8420\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.3733 - accuracy: 0.8409 - val_loss: 0.3682 - val_accuracy: 0.8420\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.3662 - accuracy: 0.8409 - val_loss: 0.3610 - val_accuracy: 0.8420\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.3590 - accuracy: 0.8409 - val_loss: 0.3538 - val_accuracy: 0.8420\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.3516 - accuracy: 0.8409 - val_loss: 0.3464 - val_accuracy: 0.8420\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.3441 - accuracy: 0.8409 - val_loss: 0.3389 - val_accuracy: 0.8420\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.3366 - accuracy: 0.8409 - val_loss: 0.3313 - val_accuracy: 0.8420\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.3289 - accuracy: 0.8409 - val_loss: 0.3238 - val_accuracy: 0.8420\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.3213 - accuracy: 0.8409 - val_loss: 0.3162 - val_accuracy: 0.8421\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.3137 - accuracy: 0.8410 - val_loss: 0.3087 - val_accuracy: 0.8425\n"
     ]
    }
   ],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "input_shape = Xtrain.shape[1:]\n",
    "n_layers = 2\n",
    "n_nodes = 50\n",
    "\n",
    "# Build and train model\n",
    "model4 = build_DNN(input_shape, n_layers, n_nodes)\n",
    "\n",
    "history4 = model4.fit(Xtrain, Ytrain, batch_size = batch_size, epochs = epochs, verbose = 2, validation_data = (Xval, Yval), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114621/114621 [==============================] - 0s 1us/step\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 50)                4650      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 7,251\n",
      "Trainable params: 7,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.3118\n",
      "Test accuracy: 0.8399\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test data\n",
    "score = model4.evaluate(Xtest, Ytest, batch_size = batch_size)\n",
    "model4.summary()\n",
    "\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(history4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 layers, 50 nodes, class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534896 samples, validate on 114620 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.4376 - accuracy: 0.8409 - val_loss: 0.4356 - val_accuracy: 0.8420\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4375 - accuracy: 0.8409 - val_loss: 0.4355 - val_accuracy: 0.8420\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4375 - accuracy: 0.8409 - val_loss: 0.4355 - val_accuracy: 0.8420\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4374 - accuracy: 0.8409 - val_loss: 0.4355 - val_accuracy: 0.8420\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4374 - accuracy: 0.8409 - val_loss: 0.4354 - val_accuracy: 0.8420\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4373 - accuracy: 0.8409 - val_loss: 0.4354 - val_accuracy: 0.8420\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4373 - accuracy: 0.8409 - val_loss: 0.4354 - val_accuracy: 0.8420\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.4373 - accuracy: 0.8409 - val_loss: 0.4353 - val_accuracy: 0.8420\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.4372 - accuracy: 0.8409 - val_loss: 0.4353 - val_accuracy: 0.8420\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.4372 - accuracy: 0.8409 - val_loss: 0.4352 - val_accuracy: 0.8420\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.4372 - accuracy: 0.8409 - val_loss: 0.4352 - val_accuracy: 0.8420\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.4371 - accuracy: 0.8409 - val_loss: 0.4352 - val_accuracy: 0.8420\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.4371 - accuracy: 0.8409 - val_loss: 0.4351 - val_accuracy: 0.8420\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.4370 - accuracy: 0.8409 - val_loss: 0.4351 - val_accuracy: 0.8420\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.4370 - accuracy: 0.8409 - val_loss: 0.4351 - val_accuracy: 0.8420\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.4370 - accuracy: 0.8409 - val_loss: 0.4350 - val_accuracy: 0.8420\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.4369 - accuracy: 0.8409 - val_loss: 0.4350 - val_accuracy: 0.8420\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.4369 - accuracy: 0.8409 - val_loss: 0.4349 - val_accuracy: 0.8420\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.4368 - accuracy: 0.8409 - val_loss: 0.4349 - val_accuracy: 0.8420\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.4368 - accuracy: 0.8409 - val_loss: 0.4348 - val_accuracy: 0.8420\n"
     ]
    }
   ],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "input_shape = Xtrain.shape[1:]\n",
    "n_layers = 4\n",
    "n_nodes = 50\n",
    "\n",
    "# Build and train model\n",
    "model5 = build_DNN(input_shape, n_layers, n_nodes)\n",
    "\n",
    "history5 = model5.fit(Xtrain, Ytrain, batch_size = batch_size, epochs = epochs, verbose = 2, validation_data = (Xval, Yval), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114621/114621 [==============================] - 0s 1us/step\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 50)                4650      \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 12,351\n",
      "Trainable params: 12,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.4387\n",
      "Test accuracy: 0.8397\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test data\n",
    "score = model5.evaluate(Xtest, Ytest, batch_size = batch_size)\n",
    "\n",
    "model5.summary()\n",
    "\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(history5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 16: Batch normalization\n",
    "\n",
    "Now add batch normalization after each dense layer. Remember to import BatchNormalization from keras.layers. \n",
    "\n",
    "See https://keras.io/layers/normalization/ for information about how to call the function.\n",
    "\n",
    "Question 18: Why is batch normalization important when training deep networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 layers, 20 nodes, class weights, batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534896 samples, validate on 114620 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 2.0438 - accuracy: 0.7070 - val_loss: 0.5663 - val_accuracy: 0.8509\n",
      "Epoch 2/20\n",
      " - 1s - loss: 1.5153 - accuracy: 0.7542 - val_loss: 0.6108 - val_accuracy: 0.8755\n",
      "Epoch 3/20\n",
      " - 1s - loss: 1.5710 - accuracy: 0.7494 - val_loss: 0.4918 - val_accuracy: 0.8774\n",
      "Epoch 4/20\n",
      " - 1s - loss: 1.4757 - accuracy: 0.7588 - val_loss: 0.6036 - val_accuracy: 0.8756\n",
      "Epoch 5/20\n",
      " - 1s - loss: 1.5553 - accuracy: 0.7585 - val_loss: 0.7439 - val_accuracy: 0.8541\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.8713 - accuracy: 0.8227 - val_loss: 0.6331 - val_accuracy: 0.8572\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.6944 - accuracy: 0.8558 - val_loss: 0.4273 - val_accuracy: 0.8551\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2469 - accuracy: 0.8979 - val_loss: 0.1879 - val_accuracy: 0.9054\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.1837 - accuracy: 0.9033 - val_loss: 0.1815 - val_accuracy: 0.9053\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.1798 - accuracy: 0.9040 - val_loss: 0.1786 - val_accuracy: 0.9051\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.1773 - accuracy: 0.9042 - val_loss: 0.1766 - val_accuracy: 0.9049\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.1759 - accuracy: 0.9042 - val_loss: 0.1752 - val_accuracy: 0.9048\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.1748 - accuracy: 0.9044 - val_loss: 0.1742 - val_accuracy: 0.9051\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.1740 - accuracy: 0.9046 - val_loss: 0.1734 - val_accuracy: 0.9053\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.1732 - accuracy: 0.9048 - val_loss: 0.1726 - val_accuracy: 0.9054\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1724 - accuracy: 0.9050 - val_loss: 0.1719 - val_accuracy: 0.9056\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1719 - accuracy: 0.9053 - val_loss: 0.1714 - val_accuracy: 0.9058\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1711 - accuracy: 0.9055 - val_loss: 0.1707 - val_accuracy: 0.9062\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1706 - accuracy: 0.9058 - val_loss: 0.1702 - val_accuracy: 0.9064\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1700 - accuracy: 0.9061 - val_loss: 0.1695 - val_accuracy: 0.9066\n"
     ]
    }
   ],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "input_shape = Xtrain.shape[1:]\n",
    "n_layers = 2\n",
    "n_nodes = 20\n",
    "\n",
    "# Build and train model\n",
    "model6 = build_DNN(input_shape, n_layers, n_nodes, use_bn = True)\n",
    "\n",
    "history6 = model6.fit(Xtrain, Ytrain, batch_size = batch_size, epochs = epochs, verbose = 2, validation_data = (Xval, Yval), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114621/114621 [==============================] - 0s 1us/step\n",
      "Test loss: 0.1575\n",
      "Test accuracy: 0.1973\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test data\n",
    "score = model6.evaluate(Xtest, Ytest, batch_size = batch_size)\n",
    "\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(history6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 17: Activation function\n",
    "\n",
    "Try changing the activation function in each layer from sigmoid to ReLU, write down the test accuracy.\n",
    "\n",
    "Note: the last layer should still have a sigmoid activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 layers, 20 nodes, class weights, ReLU, no batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534896 samples, validate on 114620 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.6482 - accuracy: 0.7180 - val_loss: 0.5170 - val_accuracy: 0.8522\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4352 - accuracy: 0.8581 - val_loss: 0.3663 - val_accuracy: 0.8635\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.3226 - accuracy: 0.8682 - val_loss: 0.2883 - val_accuracy: 0.8733\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.2664 - accuracy: 0.8765 - val_loss: 0.2502 - val_accuracy: 0.8794\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.2380 - accuracy: 0.8825 - val_loss: 0.2296 - val_accuracy: 0.8861\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.2219 - accuracy: 0.8900 - val_loss: 0.2171 - val_accuracy: 0.8930\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.2115 - accuracy: 0.8945 - val_loss: 0.2086 - val_accuracy: 0.8968\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2042 - accuracy: 0.8977 - val_loss: 0.2024 - val_accuracy: 0.9005\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.1988 - accuracy: 0.9010 - val_loss: 0.1977 - val_accuracy: 0.9025\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.1946 - accuracy: 0.9029 - val_loss: 0.1939 - val_accuracy: 0.9049\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.1912 - accuracy: 0.9045 - val_loss: 0.1908 - val_accuracy: 0.9071\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.1883 - accuracy: 0.9067 - val_loss: 0.1881 - val_accuracy: 0.9082\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.1858 - accuracy: 0.9076 - val_loss: 0.1859 - val_accuracy: 0.9096\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.1838 - accuracy: 0.9091 - val_loss: 0.1840 - val_accuracy: 0.9103\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.1820 - accuracy: 0.9091 - val_loss: 0.1823 - val_accuracy: 0.9104\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1804 - accuracy: 0.9096 - val_loss: 0.1808 - val_accuracy: 0.9106\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1790 - accuracy: 0.9098 - val_loss: 0.1795 - val_accuracy: 0.9108\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1777 - accuracy: 0.9101 - val_loss: 0.1783 - val_accuracy: 0.9110\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1766 - accuracy: 0.9104 - val_loss: 0.1773 - val_accuracy: 0.9114\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1756 - accuracy: 0.9110 - val_loss: 0.1764 - val_accuracy: 0.9120\n"
     ]
    }
   ],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "input_shape = Xtrain.shape[1:]\n",
    "n_layers = 2\n",
    "n_nodes = 20\n",
    "act_fun = 'relu'\n",
    "\n",
    "# Build and train model\n",
    "model7 = build_DNN(input_shape, n_layers, n_nodes, act_fun=act_fun)\n",
    "\n",
    "history7 = model7.fit(Xtrain, Ytrain, batch_size = batch_size, epochs = epochs, verbose = 2, validation_data = (Xval, Yval), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114621/114621 [==============================] - 0s 1us/step\n",
      "Test loss: 0.1763\n",
      "Test accuracy: 0.9112\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test data\n",
    "score = model7.evaluate(Xtest, Ytest, batch_size = batch_size)\n",
    "\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(history7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 18: Optimizer\n",
    "\n",
    "Try changing the optimizer from SGD to Adam (with learning rate 0.1 as before). Remember to import the Adam optimizer from keras.optimizers. \n",
    "\n",
    "https://keras.io/optimizers/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 layers, 20 nodes, class weights, Adam optimizer, no batch normalization, sigmoid activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534896 samples, validate on 114620 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.2643 - accuracy: 0.8637 - val_loss: 0.1804 - val_accuracy: 0.9062\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.1698 - accuracy: 0.9121 - val_loss: 0.1626 - val_accuracy: 0.9144\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.1600 - accuracy: 0.9164 - val_loss: 0.1563 - val_accuracy: 0.9173\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.1546 - accuracy: 0.9179 - val_loss: 0.1520 - val_accuracy: 0.9185\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.1509 - accuracy: 0.9189 - val_loss: 0.1489 - val_accuracy: 0.9198\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.1479 - accuracy: 0.9198 - val_loss: 0.1460 - val_accuracy: 0.9211\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.1452 - accuracy: 0.9207 - val_loss: 0.1433 - val_accuracy: 0.9226\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.1429 - accuracy: 0.9224 - val_loss: 0.1412 - val_accuracy: 0.9222\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.1407 - accuracy: 0.9243 - val_loss: 0.1390 - val_accuracy: 0.9261\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.1386 - accuracy: 0.9265 - val_loss: 0.1367 - val_accuracy: 0.9277\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.1370 - accuracy: 0.9275 - val_loss: 0.1360 - val_accuracy: 0.9298\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.1351 - accuracy: 0.9291 - val_loss: 0.1335 - val_accuracy: 0.9287\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.1333 - accuracy: 0.9305 - val_loss: 0.1322 - val_accuracy: 0.9342\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.1319 - accuracy: 0.9310 - val_loss: 0.1313 - val_accuracy: 0.9324\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.1303 - accuracy: 0.9323 - val_loss: 0.1287 - val_accuracy: 0.9332\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.1288 - accuracy: 0.9333 - val_loss: 0.1276 - val_accuracy: 0.9352\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.1273 - accuracy: 0.9343 - val_loss: 0.1250 - val_accuracy: 0.9357\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.1256 - accuracy: 0.9352 - val_loss: 0.1253 - val_accuracy: 0.9323\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.1244 - accuracy: 0.9359 - val_loss: 0.1229 - val_accuracy: 0.9363\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.1230 - accuracy: 0.9367 - val_loss: 0.1211 - val_accuracy: 0.9389\n"
     ]
    }
   ],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "input_shape = Xtrain.shape[1:]\n",
    "n_layers = 2\n",
    "n_nodes = 20\n",
    "\n",
    "# Build and train model\n",
    "model8 = build_DNN(input_shape, n_layers, n_nodes, optimizer = 'adam')\n",
    "\n",
    "history8 = model8.fit(Xtrain, Ytrain, batch_size = batch_size, epochs = epochs, verbose = 2, validation_data = (Xval, Yval), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114621/114621 [==============================] - 0s 1us/step\n",
      "Test loss: 0.1225\n",
      "Test accuracy: 0.9379\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test data\n",
    "score = model8.evaluate(Xtest, Ytest, batch_size = batch_size)\n",
    "\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(history8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 19: Dropout regularization\n",
    "\n",
    "Dropout is a type of regularization that can improve accuracy for validation and test data. \n",
    "\n",
    "Add a Dropout layer after each Dense layer (but not after the final dense layer), with a dropout probability of 50%. Remember to first import the Dropout layer from keras.layers\n",
    "\n",
    "See https://keras.io/layers/core/ for how the Dropout layer works.\n",
    "\n",
    "---\n",
    "\n",
    "Question 19: How does the validation accuracy change when adding dropout?\n",
    "\n",
    "Question 20: How does the test accuracy change when adding dropout?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 layers, 20 nodes, class weights, dropout, SGD optimizer, no batch normalization, sigmoid activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534896 samples, validate on 114620 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.6554 - accuracy: 0.6168 - val_loss: 0.5023 - val_accuracy: 0.8420\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.5080 - accuracy: 0.8007 - val_loss: 0.4446 - val_accuracy: 0.8420\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4723 - accuracy: 0.8298 - val_loss: 0.4286 - val_accuracy: 0.8420\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4598 - accuracy: 0.8363 - val_loss: 0.4225 - val_accuracy: 0.8420\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4530 - accuracy: 0.8384 - val_loss: 0.4193 - val_accuracy: 0.8420\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4498 - accuracy: 0.8393 - val_loss: 0.4170 - val_accuracy: 0.8420\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4466 - accuracy: 0.8396 - val_loss: 0.4149 - val_accuracy: 0.8420\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.4438 - accuracy: 0.8401 - val_loss: 0.4130 - val_accuracy: 0.8420\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.4418 - accuracy: 0.8403 - val_loss: 0.4110 - val_accuracy: 0.8420\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.4392 - accuracy: 0.8402 - val_loss: 0.4091 - val_accuracy: 0.8420\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.4365 - accuracy: 0.8404 - val_loss: 0.4072 - val_accuracy: 0.8420\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.4347 - accuracy: 0.8404 - val_loss: 0.4053 - val_accuracy: 0.8420\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.4327 - accuracy: 0.8404 - val_loss: 0.4034 - val_accuracy: 0.8420\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.4310 - accuracy: 0.8405 - val_loss: 0.4015 - val_accuracy: 0.8420\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.4281 - accuracy: 0.8406 - val_loss: 0.3996 - val_accuracy: 0.8420\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.4263 - accuracy: 0.8405 - val_loss: 0.3977 - val_accuracy: 0.8420\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.4245 - accuracy: 0.8406 - val_loss: 0.3957 - val_accuracy: 0.8420\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.4224 - accuracy: 0.8407 - val_loss: 0.3938 - val_accuracy: 0.8420\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.4200 - accuracy: 0.8407 - val_loss: 0.3918 - val_accuracy: 0.8420\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.4186 - accuracy: 0.8407 - val_loss: 0.3897 - val_accuracy: 0.8420\n"
     ]
    }
   ],
   "source": [
    "# Setup some training parameters\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "input_shape = Xtrain.shape[1:]\n",
    "n_layers = 2\n",
    "n_nodes = 20\n",
    "\n",
    "# Build and train model\n",
    "model9 = build_DNN(input_shape, n_layers, n_nodes, use_dropout=True, optimizer = 'sgd')\n",
    "\n",
    "history9 = model9.fit(Xtrain, Ytrain, batch_size = batch_size, epochs = epochs, verbose = 2, validation_data = (Xval, Yval), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114621/114621 [==============================] - 0s 1us/step\n",
      "Test loss: 0.3935\n",
      "Test accuracy: 0.8397\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test data\n",
    "score = model9.evaluate(Xtest, Ytest, batch_size = batch_size)\n",
    "\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(history9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 20: Improving performance\n",
    "\n",
    "Spend some time (30 - 90 minutes) playing with the network architecture (number of layers, number of nodes per layer, activation function) and other hyper parameters (optimizer, learning rate, batch size, number of epochs, degree of regularization). For example, try a much deeper network. How much does the training time increase for a network with 10 layers?\n",
    "\n",
    "Question 21: How high classification accuracy can you achieve for the test data? What is your best configuration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534896 samples, validate on 114620 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.2039 - accuracy: 0.9049 - val_loss: 0.1518 - val_accuracy: 0.9188\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.1481 - accuracy: 0.9190 - val_loss: 0.1456 - val_accuracy: 0.9207\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.1442 - accuracy: 0.9213 - val_loss: 0.1437 - val_accuracy: 0.9223\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.1416 - accuracy: 0.9227 - val_loss: 0.1389 - val_accuracy: 0.9263\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.1389 - accuracy: 0.9250 - val_loss: 0.1361 - val_accuracy: 0.9263\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1373 - accuracy: 0.9258 - val_loss: 0.1337 - val_accuracy: 0.9300\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1350 - accuracy: 0.9277 - val_loss: 0.1318 - val_accuracy: 0.9310\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1326 - accuracy: 0.9297 - val_loss: 0.1286 - val_accuracy: 0.9322\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1288 - accuracy: 0.9322 - val_loss: 0.1253 - val_accuracy: 0.9342\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1261 - accuracy: 0.9342 - val_loss: 0.1236 - val_accuracy: 0.9355\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1237 - accuracy: 0.9356 - val_loss: 0.1187 - val_accuracy: 0.9405\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1205 - accuracy: 0.9371 - val_loss: 0.1175 - val_accuracy: 0.9396\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1187 - accuracy: 0.9380 - val_loss: 0.1157 - val_accuracy: 0.9405\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1168 - accuracy: 0.9392 - val_loss: 0.1145 - val_accuracy: 0.9420\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1158 - accuracy: 0.9395 - val_loss: 0.1141 - val_accuracy: 0.9381\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.1157 - accuracy: 0.9384 - val_loss: 0.1128 - val_accuracy: 0.9424\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.1143 - accuracy: 0.9401 - val_loss: 0.1107 - val_accuracy: 0.9414\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.1133 - accuracy: 0.9400 - val_loss: 0.1125 - val_accuracy: 0.9390\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.1133 - accuracy: 0.9400 - val_loss: 0.1136 - val_accuracy: 0.9320\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.1118 - accuracy: 0.9411 - val_loss: 0.1090 - val_accuracy: 0.9440\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.1117 - accuracy: 0.9409 - val_loss: 0.1092 - val_accuracy: 0.9435\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.1119 - accuracy: 0.9406 - val_loss: 0.1087 - val_accuracy: 0.9418\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.1131 - accuracy: 0.9388 - val_loss: 0.1128 - val_accuracy: 0.9366\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.1106 - accuracy: 0.9411 - val_loss: 0.1085 - val_accuracy: 0.9411\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.1104 - accuracy: 0.9413 - val_loss: 0.1080 - val_accuracy: 0.9439\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.1107 - accuracy: 0.9409 - val_loss: 0.1098 - val_accuracy: 0.9411\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.1104 - accuracy: 0.9415 - val_loss: 0.1078 - val_accuracy: 0.9428\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.1094 - accuracy: 0.9418 - val_loss: 0.1064 - val_accuracy: 0.9444\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.1092 - accuracy: 0.9419 - val_loss: 0.1090 - val_accuracy: 0.9417\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.1090 - accuracy: 0.9421 - val_loss: 0.1062 - val_accuracy: 0.9448\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.1090 - accuracy: 0.9426 - val_loss: 0.1062 - val_accuracy: 0.9428\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.1086 - accuracy: 0.9427 - val_loss: 0.1067 - val_accuracy: 0.9453\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.1094 - accuracy: 0.9417 - val_loss: 0.1068 - val_accuracy: 0.9432\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.1098 - accuracy: 0.9408 - val_loss: 0.1064 - val_accuracy: 0.9443\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.1092 - accuracy: 0.9411 - val_loss: 0.1064 - val_accuracy: 0.9431\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.1082 - accuracy: 0.9425 - val_loss: 0.1076 - val_accuracy: 0.9405\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.1077 - accuracy: 0.9431 - val_loss: 0.1067 - val_accuracy: 0.9437\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.1082 - accuracy: 0.9421 - val_loss: 0.1077 - val_accuracy: 0.9417\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.1072 - accuracy: 0.9432 - val_loss: 0.1046 - val_accuracy: 0.9444\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.1076 - accuracy: 0.9429 - val_loss: 0.1047 - val_accuracy: 0.9448\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.1071 - accuracy: 0.9430 - val_loss: 0.1082 - val_accuracy: 0.9414\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.1082 - accuracy: 0.9423 - val_loss: 0.1085 - val_accuracy: 0.9416\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.1074 - accuracy: 0.9426 - val_loss: 0.1039 - val_accuracy: 0.9450\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.1066 - accuracy: 0.9432 - val_loss: 0.1053 - val_accuracy: 0.9433\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.1076 - accuracy: 0.9425 - val_loss: 0.1061 - val_accuracy: 0.9424\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.1067 - accuracy: 0.9425 - val_loss: 0.1055 - val_accuracy: 0.9421\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.1062 - accuracy: 0.9436 - val_loss: 0.1098 - val_accuracy: 0.9336\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.1071 - accuracy: 0.9424 - val_loss: 0.1050 - val_accuracy: 0.9452\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.1082 - accuracy: 0.9423 - val_loss: 0.1063 - val_accuracy: 0.9427\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.1080 - accuracy: 0.9418 - val_loss: 0.1130 - val_accuracy: 0.9318\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.1076 - accuracy: 0.9416 - val_loss: 0.1029 - val_accuracy: 0.9459\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.1059 - accuracy: 0.9438 - val_loss: 0.1053 - val_accuracy: 0.9401\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.1051 - accuracy: 0.9448 - val_loss: 0.1051 - val_accuracy: 0.9426\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.1056 - accuracy: 0.9436 - val_loss: 0.1076 - val_accuracy: 0.9386\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.1072 - accuracy: 0.9425 - val_loss: 0.1022 - val_accuracy: 0.9460\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.1072 - accuracy: 0.9437 - val_loss: 0.1052 - val_accuracy: 0.9438\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.1064 - accuracy: 0.9436 - val_loss: 0.1043 - val_accuracy: 0.9441\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.1058 - accuracy: 0.9437 - val_loss: 0.1019 - val_accuracy: 0.9471\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.1047 - accuracy: 0.9444 - val_loss: 0.1040 - val_accuracy: 0.9442\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.1074 - accuracy: 0.9416 - val_loss: 0.1023 - val_accuracy: 0.9459\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.1045 - accuracy: 0.9450 - val_loss: 0.1033 - val_accuracy: 0.9451\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.1045 - accuracy: 0.9440 - val_loss: 0.1021 - val_accuracy: 0.9464\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.1047 - accuracy: 0.9438 - val_loss: 0.1023 - val_accuracy: 0.9446\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.1048 - accuracy: 0.9441 - val_loss: 0.1023 - val_accuracy: 0.9456\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.1054 - accuracy: 0.9434 - val_loss: 0.1053 - val_accuracy: 0.9374\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.1058 - accuracy: 0.9431 - val_loss: 0.1023 - val_accuracy: 0.9462\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.1045 - accuracy: 0.9443 - val_loss: 0.1045 - val_accuracy: 0.9428\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.1051 - accuracy: 0.9430 - val_loss: 0.1030 - val_accuracy: 0.9460\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.1036 - accuracy: 0.9454 - val_loss: 0.1045 - val_accuracy: 0.9385\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.1043 - accuracy: 0.9445 - val_loss: 0.1016 - val_accuracy: 0.9466\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.1049 - accuracy: 0.9435 - val_loss: 0.1013 - val_accuracy: 0.9461\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.1034 - accuracy: 0.9457 - val_loss: 0.1068 - val_accuracy: 0.9423\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.1037 - accuracy: 0.9450 - val_loss: 0.1020 - val_accuracy: 0.9464\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.1041 - accuracy: 0.9438 - val_loss: 0.1014 - val_accuracy: 0.9466\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.1033 - accuracy: 0.9452 - val_loss: 0.1023 - val_accuracy: 0.9454\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.1042 - accuracy: 0.9445 - val_loss: 0.1009 - val_accuracy: 0.9469\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.1033 - accuracy: 0.9451 - val_loss: 0.1070 - val_accuracy: 0.9375\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.1051 - accuracy: 0.9438 - val_loss: 0.1051 - val_accuracy: 0.9434\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.1040 - accuracy: 0.9446 - val_loss: 0.1007 - val_accuracy: 0.9478\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.1038 - accuracy: 0.9447 - val_loss: 0.1011 - val_accuracy: 0.9471\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.1052 - accuracy: 0.9429 - val_loss: 0.1018 - val_accuracy: 0.9450\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.1037 - accuracy: 0.9443 - val_loss: 0.1025 - val_accuracy: 0.9444\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.1047 - accuracy: 0.9430 - val_loss: 0.1028 - val_accuracy: 0.9424\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.1042 - accuracy: 0.9441 - val_loss: 0.1014 - val_accuracy: 0.9463\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.1033 - accuracy: 0.9454 - val_loss: 0.1019 - val_accuracy: 0.9447\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.1034 - accuracy: 0.9451 - val_loss: 0.1015 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 1s - loss: 0.1033 - accuracy: 0.9446 - val_loss: 0.1025 - val_accuracy: 0.9427\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.1030 - accuracy: 0.9451 - val_loss: 0.0994 - val_accuracy: 0.9486\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.1031 - accuracy: 0.9447 - val_loss: 0.1041 - val_accuracy: 0.9387\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.1034 - accuracy: 0.9450 - val_loss: 0.1001 - val_accuracy: 0.9477\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.1026 - accuracy: 0.9453 - val_loss: 0.1010 - val_accuracy: 0.9457\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.1028 - accuracy: 0.9452 - val_loss: 0.0998 - val_accuracy: 0.9466\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.1020 - accuracy: 0.9454 - val_loss: 0.1011 - val_accuracy: 0.9482\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.1028 - accuracy: 0.9453 - val_loss: 0.1010 - val_accuracy: 0.9457\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.1021 - accuracy: 0.9462 - val_loss: 0.1006 - val_accuracy: 0.9458\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.1023 - accuracy: 0.9452 - val_loss: 0.1012 - val_accuracy: 0.9455\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.1022 - accuracy: 0.9449 - val_loss: 0.1001 - val_accuracy: 0.9464\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.1019 - accuracy: 0.9454 - val_loss: 0.1002 - val_accuracy: 0.9474\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.1044 - accuracy: 0.9434 - val_loss: 0.1014 - val_accuracy: 0.9443\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.1042 - accuracy: 0.9439 - val_loss: 0.1033 - val_accuracy: 0.9451\n"
     ]
    }
   ],
   "source": [
    "# Find your best configuration for the DNN\n",
    "batch_size = 10000\n",
    "epochs = 100\n",
    "input_shape = Xtrain.shape[1:]\n",
    "n_layers = 2\n",
    "n_nodes = 20\n",
    "act_fun = 'relu'\n",
    "\n",
    "# Build and train model\n",
    "model10 =  build_DNN(input_shape, n_layers, n_nodes, optimizer = 'adam', act_fun = act_fun)\n",
    "\n",
    "history10 =  model10.fit(Xtrain, Ytrain, batch_size = batch_size, epochs = epochs, verbose = 2, validation_data = (Xval, Yval), class_weight = class_weights)\n",
    "# Build and train DNN\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114621/114621 [==============================] - 0s 1us/step\n",
      "Test loss: 0.1057\n",
      "Test accuracy: 0.9435\n"
     ]
    }
   ],
   "source": [
    "# Evaluate DNN on test data\n",
    "score = model10.evaluate(Xtest, Ytest, batch_size = batch_size)\n",
    "\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 21: Dropout uncertainty\n",
    "\n",
    "Dropout can also be used during testing, to obtain an estimate of the model uncertainty. Since dropout will randomly remove connections, the network will produce different results every time the same (test) data is put into the network. This technique is called Monte Carlo dropout. For more information, see this paper http://proceedings.mlr.press/v48/gal16.pdf\n",
    "\n",
    "To achieve this, we need to redefine the Keras Dropout call by running the cell below, and use 'myDropout' in each call to Dropout, in the cell that defines the DNN.\n",
    "\n",
    "Run the same test data through the trained network 100 times, with dropout turned on. \n",
    "\n",
    "Question 22: What is the mean and the standard deviation of the test accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "class myDropout(keras.layers.Dropout):\n",
    "    \"\"\"Applies Dropout to the input.\n",
    "    Dropout consists in randomly setting\n",
    "    a fraction `rate` of input units to 0 at each update during training time,\n",
    "    which helps prevent overfitting.\n",
    "    # Arguments\n",
    "        rate: float between 0 and 1. Fraction of the input units to drop.\n",
    "        noise_shape: 1D integer tensor representing the shape of the\n",
    "            binary dropout mask that will be multiplied with the input.\n",
    "            For instance, if your inputs have shape\n",
    "            `(batch_size, timesteps, features)` and\n",
    "            you want the dropout mask to be the same for all timesteps,\n",
    "            you can use `noise_shape=(batch_size, 1, features)`.\n",
    "        seed: A Python integer to use as random seed.\n",
    "    # References\n",
    "        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](\n",
    "           http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n",
    "    \"\"\"\n",
    "    def __init__(self, rate, training=True, noise_shape=None, seed=None, **kwargs):\n",
    "        super(myDropout, self).__init__(rate, noise_shape=None, seed=None,**kwargs)\n",
    "        self.training = training\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        if 0. < self.rate < 1.:\n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "\n",
    "            def dropped_inputs():\n",
    "                return K.dropout(inputs, self.rate, noise_shape,\n",
    "                                 seed=self.seed)\n",
    "            if not training: \n",
    "                return K.in_train_phase(dropped_inputs, inputs, training=self.training)\n",
    "            return K.in_train_phase(dropped_inputs, inputs, training=training)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your best config, custom dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 687724 samples, validate on 114620 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.2602 - accuracy: 0.8671 - val_loss: 0.1766 - val_accuracy: 0.9011\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.1688 - accuracy: 0.9064 - val_loss: 0.1672 - val_accuracy: 0.9100\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.1632 - accuracy: 0.9119 - val_loss: 0.1614 - val_accuracy: 0.9136\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.1588 - accuracy: 0.9148 - val_loss: 0.1584 - val_accuracy: 0.9159\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.1555 - accuracy: 0.9156 - val_loss: 0.1536 - val_accuracy: 0.9165\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1545 - accuracy: 0.9159 - val_loss: 0.1514 - val_accuracy: 0.9162\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1528 - accuracy: 0.9168 - val_loss: 0.1529 - val_accuracy: 0.9176\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1520 - accuracy: 0.9165 - val_loss: 0.1518 - val_accuracy: 0.9171\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1505 - accuracy: 0.9163 - val_loss: 0.1512 - val_accuracy: 0.9176\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1497 - accuracy: 0.9175 - val_loss: 0.1495 - val_accuracy: 0.9174\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1486 - accuracy: 0.9175 - val_loss: 0.1466 - val_accuracy: 0.9178\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1472 - accuracy: 0.9185 - val_loss: 0.1483 - val_accuracy: 0.9189\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1474 - accuracy: 0.9186 - val_loss: 0.1488 - val_accuracy: 0.9177\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1473 - accuracy: 0.9183 - val_loss: 0.1484 - val_accuracy: 0.9199\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1467 - accuracy: 0.9189 - val_loss: 0.1455 - val_accuracy: 0.9185\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.1463 - accuracy: 0.9188 - val_loss: 0.1463 - val_accuracy: 0.9176\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.1470 - accuracy: 0.9181 - val_loss: 0.1459 - val_accuracy: 0.9184\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.1454 - accuracy: 0.9187 - val_loss: 0.1462 - val_accuracy: 0.9179\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.1447 - accuracy: 0.9194 - val_loss: 0.1449 - val_accuracy: 0.9196\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.1448 - accuracy: 0.9195 - val_loss: 0.1472 - val_accuracy: 0.9205\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.1447 - accuracy: 0.9186 - val_loss: 0.1447 - val_accuracy: 0.9196\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.1448 - accuracy: 0.9185 - val_loss: 0.1429 - val_accuracy: 0.9191\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.1440 - accuracy: 0.9184 - val_loss: 0.1437 - val_accuracy: 0.9188\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.1438 - accuracy: 0.9198 - val_loss: 0.1440 - val_accuracy: 0.9194\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.1440 - accuracy: 0.9190 - val_loss: 0.1422 - val_accuracy: 0.9204\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.1438 - accuracy: 0.9195 - val_loss: 0.1446 - val_accuracy: 0.9193\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.1436 - accuracy: 0.9196 - val_loss: 0.1434 - val_accuracy: 0.9193\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.1445 - accuracy: 0.9194 - val_loss: 0.1430 - val_accuracy: 0.9197\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.1436 - accuracy: 0.9197 - val_loss: 0.1416 - val_accuracy: 0.9199\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.1440 - accuracy: 0.9197 - val_loss: 0.1432 - val_accuracy: 0.9199\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.1432 - accuracy: 0.9202 - val_loss: 0.1433 - val_accuracy: 0.9200\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.1432 - accuracy: 0.9202 - val_loss: 0.1441 - val_accuracy: 0.9199\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.1429 - accuracy: 0.9204 - val_loss: 0.1432 - val_accuracy: 0.9209\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.1427 - accuracy: 0.9206 - val_loss: 0.1413 - val_accuracy: 0.9209\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.1425 - accuracy: 0.9211 - val_loss: 0.1433 - val_accuracy: 0.9218\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.1431 - accuracy: 0.9201 - val_loss: 0.1439 - val_accuracy: 0.9195\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.1419 - accuracy: 0.9202 - val_loss: 0.1421 - val_accuracy: 0.9217\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.1422 - accuracy: 0.9205 - val_loss: 0.1400 - val_accuracy: 0.9211\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.1412 - accuracy: 0.9211 - val_loss: 0.1406 - val_accuracy: 0.9219\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.1415 - accuracy: 0.9218 - val_loss: 0.1421 - val_accuracy: 0.9216\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.1412 - accuracy: 0.9210 - val_loss: 0.1394 - val_accuracy: 0.9219\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.1416 - accuracy: 0.9215 - val_loss: 0.1394 - val_accuracy: 0.9228\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.1414 - accuracy: 0.9220 - val_loss: 0.1405 - val_accuracy: 0.9219\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.1421 - accuracy: 0.9202 - val_loss: 0.1418 - val_accuracy: 0.9193\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.1416 - accuracy: 0.9209 - val_loss: 0.1414 - val_accuracy: 0.9219\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.1407 - accuracy: 0.9223 - val_loss: 0.1392 - val_accuracy: 0.9227\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.1412 - accuracy: 0.9222 - val_loss: 0.1398 - val_accuracy: 0.9235\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.1415 - accuracy: 0.9219 - val_loss: 0.1412 - val_accuracy: 0.9229\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.1403 - accuracy: 0.9225 - val_loss: 0.1398 - val_accuracy: 0.9242\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.1413 - accuracy: 0.9215 - val_loss: 0.1399 - val_accuracy: 0.9218\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.1404 - accuracy: 0.9221 - val_loss: 0.1398 - val_accuracy: 0.9218\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.1405 - accuracy: 0.9225 - val_loss: 0.1401 - val_accuracy: 0.9222\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.1407 - accuracy: 0.9223 - val_loss: 0.1391 - val_accuracy: 0.9227\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.1404 - accuracy: 0.9227 - val_loss: 0.1380 - val_accuracy: 0.9247\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.1413 - accuracy: 0.9227 - val_loss: 0.1393 - val_accuracy: 0.9221\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.1404 - accuracy: 0.9227 - val_loss: 0.1392 - val_accuracy: 0.9240\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.1406 - accuracy: 0.9227 - val_loss: 0.1404 - val_accuracy: 0.9219\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.1412 - accuracy: 0.9220 - val_loss: 0.1409 - val_accuracy: 0.9224\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.1410 - accuracy: 0.9222 - val_loss: 0.1398 - val_accuracy: 0.9232\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.1404 - accuracy: 0.9229 - val_loss: 0.1425 - val_accuracy: 0.9216\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.1418 - accuracy: 0.9220 - val_loss: 0.1403 - val_accuracy: 0.9226\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.1409 - accuracy: 0.9223 - val_loss: 0.1412 - val_accuracy: 0.9224\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.1412 - accuracy: 0.9215 - val_loss: 0.1420 - val_accuracy: 0.9228\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.1399 - accuracy: 0.9224 - val_loss: 0.1411 - val_accuracy: 0.9220\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.1405 - accuracy: 0.9224 - val_loss: 0.1417 - val_accuracy: 0.9232\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.1408 - accuracy: 0.9217 - val_loss: 0.1396 - val_accuracy: 0.9233\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.1399 - accuracy: 0.9230 - val_loss: 0.1383 - val_accuracy: 0.9236\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.1398 - accuracy: 0.9229 - val_loss: 0.1400 - val_accuracy: 0.9238\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.1396 - accuracy: 0.9228 - val_loss: 0.1379 - val_accuracy: 0.9233\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.1397 - accuracy: 0.9230 - val_loss: 0.1396 - val_accuracy: 0.9222\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.1396 - accuracy: 0.9235 - val_loss: 0.1389 - val_accuracy: 0.9244\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.1408 - accuracy: 0.9234 - val_loss: 0.1403 - val_accuracy: 0.9244\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.1401 - accuracy: 0.9236 - val_loss: 0.1374 - val_accuracy: 0.9258\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.1394 - accuracy: 0.9233 - val_loss: 0.1380 - val_accuracy: 0.9251\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.1396 - accuracy: 0.9233 - val_loss: 0.1383 - val_accuracy: 0.9243\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.1403 - accuracy: 0.9229 - val_loss: 0.1415 - val_accuracy: 0.9238\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.1395 - accuracy: 0.9234 - val_loss: 0.1381 - val_accuracy: 0.9240\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.1402 - accuracy: 0.9223 - val_loss: 0.1399 - val_accuracy: 0.9229\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.1396 - accuracy: 0.9233 - val_loss: 0.1411 - val_accuracy: 0.9246\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.1390 - accuracy: 0.9230 - val_loss: 0.1375 - val_accuracy: 0.9244\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.1392 - accuracy: 0.9230 - val_loss: 0.1395 - val_accuracy: 0.9243\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.1400 - accuracy: 0.9231 - val_loss: 0.1406 - val_accuracy: 0.9251\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.1401 - accuracy: 0.9235 - val_loss: 0.1386 - val_accuracy: 0.9252\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.1389 - accuracy: 0.9240 - val_loss: 0.1383 - val_accuracy: 0.9245\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.1395 - accuracy: 0.9239 - val_loss: 0.1379 - val_accuracy: 0.9248\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.1388 - accuracy: 0.9240 - val_loss: 0.1393 - val_accuracy: 0.9232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 1s - loss: 0.1394 - accuracy: 0.9237 - val_loss: 0.1392 - val_accuracy: 0.9243\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.1390 - accuracy: 0.9238 - val_loss: 0.1400 - val_accuracy: 0.9247\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.1392 - accuracy: 0.9235 - val_loss: 0.1368 - val_accuracy: 0.9255\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.1395 - accuracy: 0.9229 - val_loss: 0.1406 - val_accuracy: 0.9227\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.1393 - accuracy: 0.9237 - val_loss: 0.1387 - val_accuracy: 0.9231\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.1390 - accuracy: 0.9234 - val_loss: 0.1430 - val_accuracy: 0.9229\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.1395 - accuracy: 0.9225 - val_loss: 0.1388 - val_accuracy: 0.9239\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.1399 - accuracy: 0.9235 - val_loss: 0.1381 - val_accuracy: 0.9238\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.1392 - accuracy: 0.9235 - val_loss: 0.1390 - val_accuracy: 0.9237\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.1394 - accuracy: 0.9234 - val_loss: 0.1404 - val_accuracy: 0.9238\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.1395 - accuracy: 0.9237 - val_loss: 0.1377 - val_accuracy: 0.9248\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.1395 - accuracy: 0.9234 - val_loss: 0.1384 - val_accuracy: 0.9223\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.1394 - accuracy: 0.9232 - val_loss: 0.1381 - val_accuracy: 0.9235\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.1391 - accuracy: 0.9236 - val_loss: 0.1380 - val_accuracy: 0.9243\n"
     ]
    }
   ],
   "source": [
    "# Your best training parameters\n",
    "batch_size = 10000\n",
    "epochs = 100\n",
    "input_shape = Xtrain.shape[1:]\n",
    "n_layers = 2\n",
    "n_nodes = 20\n",
    "act_fun = 'relu'\n",
    "\n",
    "# Build and train model\n",
    "model11 = build_DNN(input_shape, n_layers, n_nodes, optimizer = 'adam', act_fun = act_fun, use_custom_dropout = True)\n",
    "\n",
    "history11 = model11.fit(Xtrain, Ytrain, batch_size = batch_size, epochs = epochs, verbose = 2, validation_data = (Xval, Yval), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76413/76413 [==============================] - 0s 1us/step\n",
      "Test accuracy: 0.9232\n"
     ]
    }
   ],
   "source": [
    "# Run this cell a few times to evalute the model on test data, \n",
    "# if you get slightly different test accuracy every time, Dropout during testing is working\n",
    "\n",
    "# Evaluate model on test data\n",
    "score = model11.evaluate(Xtest, Ytest, batch_size = batch_size)\n",
    "                       \n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "The mean is:  0.9230145424604416\n",
      "The standard deviation is:  0.0004875418457955716\n"
     ]
    }
   ],
   "source": [
    "# Run the testing 100 times, and save the accuracies in an array\n",
    "\n",
    "accuracies = []\n",
    "for i in range(100):\n",
    "    score =  model11.evaluate(Xtest, Ytest, batch_size = batch_size, verbose = 0)\n",
    "    accuracies.append(score[1])\n",
    "\n",
    "print(\"The mean is: \", np.mean(accuracies))\n",
    "print(\"The standard deviation is: \", np.std(accuracies))\n",
    "# Calculate and print mean and std of accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 22: Cross validation uncertainty\n",
    "\n",
    "Cross validation (CV) is often used to evaluate a model, by training and testing using different subsets of the data it is possible to get the uncertainty as the standard deviation over folds. We here use a help function from scikit-learn to setup the CV, see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html . Use 10 folds with shuffling, random state 1234. \n",
    "\n",
    "Note: We here assume that you have found the best hyper parameters, so here the data are only split into training and testing, no validation.\n",
    "\n",
    "---\n",
    "\n",
    "Question 23: What is the mean and the standard deviation of the test accuracy?\n",
    "\n",
    "Question 24: What is the main advantage of dropout compared to CV for estimating test uncertainty?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 1s - loss: 0.4932 - accuracy: 0.8408\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4589 - accuracy: 0.8408\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4490 - accuracy: 0.8408\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4436 - accuracy: 0.8408\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4391 - accuracy: 0.8408\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4349 - accuracy: 0.8408\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4307 - accuracy: 0.8408\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.4266 - accuracy: 0.8408\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.4224 - accuracy: 0.8408\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.4181 - accuracy: 0.8408\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.4137 - accuracy: 0.8408\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.4092 - accuracy: 0.8408\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.4045 - accuracy: 0.8408\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.3997 - accuracy: 0.8408\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.3947 - accuracy: 0.8408\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.3895 - accuracy: 0.8408\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.3840 - accuracy: 0.8408\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.3784 - accuracy: 0.8408\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.3726 - accuracy: 0.8408\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.3666 - accuracy: 0.8408\n",
      "76415/76415 [==============================] - 0s 1us/step\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.5545 - accuracy: 0.7909\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4483 - accuracy: 0.8408\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4323 - accuracy: 0.8408\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4268 - accuracy: 0.8408\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4232 - accuracy: 0.8408\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4198 - accuracy: 0.8408\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4164 - accuracy: 0.8408\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.4130 - accuracy: 0.8408\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.4093 - accuracy: 0.8408\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.4056 - accuracy: 0.8408\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.4016 - accuracy: 0.8408\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.3975 - accuracy: 0.8408\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.3932 - accuracy: 0.8408\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.3887 - accuracy: 0.8408\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.3839 - accuracy: 0.8408\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.3790 - accuracy: 0.8408\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.3738 - accuracy: 0.8408\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.3684 - accuracy: 0.8408\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.3628 - accuracy: 0.8408\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.3570 - accuracy: 0.8408\n",
      "76414/76414 [==============================] - 0s 1us/step\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.8146 - accuracy: 0.4482\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4785 - accuracy: 0.8408\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4354 - accuracy: 0.8408\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4239 - accuracy: 0.8408\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4177 - accuracy: 0.8408\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4126 - accuracy: 0.8408\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4078 - accuracy: 0.8408\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.4029 - accuracy: 0.8408\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.3980 - accuracy: 0.8408\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.3929 - accuracy: 0.8408\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.3878 - accuracy: 0.8408\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.3825 - accuracy: 0.8408\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.3771 - accuracy: 0.8408\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.3715 - accuracy: 0.8408\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.3658 - accuracy: 0.8408\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.3600 - accuracy: 0.8408\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.3540 - accuracy: 0.8408\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.3480 - accuracy: 0.8408\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.3418 - accuracy: 0.8408\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.3355 - accuracy: 0.8408\n",
      "76414/76414 [==============================] - 0s 1us/step\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.7442 - accuracy: 0.5121\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4745 - accuracy: 0.8408\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4390 - accuracy: 0.8408\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4289 - accuracy: 0.8408\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4231 - accuracy: 0.8408\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4181 - accuracy: 0.8408\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4134 - accuracy: 0.8408\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.4086 - accuracy: 0.8408\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.4036 - accuracy: 0.8408\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.3985 - accuracy: 0.8408\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.3932 - accuracy: 0.8408\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.3876 - accuracy: 0.8408\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.3819 - accuracy: 0.8408\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.3759 - accuracy: 0.8408\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.3696 - accuracy: 0.8408\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.3632 - accuracy: 0.8408\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.3565 - accuracy: 0.8408\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.3496 - accuracy: 0.8408\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.3425 - accuracy: 0.8408\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.3353 - accuracy: 0.8408\n",
      "76414/76414 [==============================] - 0s 1us/step\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.5418 - accuracy: 0.8407\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4540 - accuracy: 0.8408\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4355 - accuracy: 0.8408\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4275 - accuracy: 0.8408\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4217 - accuracy: 0.8408\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4163 - accuracy: 0.8408\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4110 - accuracy: 0.8408\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.4056 - accuracy: 0.8408\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.4001 - accuracy: 0.8408\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.3944 - accuracy: 0.8408\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.3887 - accuracy: 0.8408\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.3827 - accuracy: 0.8408\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.3767 - accuracy: 0.8408\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.3704 - accuracy: 0.8408\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.3640 - accuracy: 0.8408\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.3574 - accuracy: 0.8408\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.3507 - accuracy: 0.8408\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.3439 - accuracy: 0.8408\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.3369 - accuracy: 0.8408\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.3300 - accuracy: 0.8408\n",
      "76414/76414 [==============================] - 0s 1us/step\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.6455 - accuracy: 0.6321\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4679 - accuracy: 0.8408\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4429 - accuracy: 0.8408\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4343 - accuracy: 0.8408\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4284 - accuracy: 0.8408\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4230 - accuracy: 0.8408\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4176 - accuracy: 0.8408\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.4121 - accuracy: 0.8408\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.4064 - accuracy: 0.8408\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.4004 - accuracy: 0.8408\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.3942 - accuracy: 0.8408\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.3877 - accuracy: 0.8408\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.3809 - accuracy: 0.8408\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.3738 - accuracy: 0.8408\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.3665 - accuracy: 0.8408\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.3590 - accuracy: 0.8408\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.3513 - accuracy: 0.8408\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.3435 - accuracy: 0.8408\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.3355 - accuracy: 0.8408\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.3274 - accuracy: 0.8408\n",
      "76414/76414 [==============================] - 0s 1us/step\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.5087 - accuracy: 0.8408\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4427 - accuracy: 0.8408\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4302 - accuracy: 0.8408\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8408\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4208 - accuracy: 0.8408\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4169 - accuracy: 0.8408\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4130 - accuracy: 0.8408\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.4089 - accuracy: 0.8408\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.4046 - accuracy: 0.8408\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.4002 - accuracy: 0.8408\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.3955 - accuracy: 0.8408\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.3906 - accuracy: 0.8408\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.3854 - accuracy: 0.8408\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.3800 - accuracy: 0.8408\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.3744 - accuracy: 0.8408\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.3684 - accuracy: 0.8408\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.3623 - accuracy: 0.8408\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.3559 - accuracy: 0.8408\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.3492 - accuracy: 0.8408\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.3424 - accuracy: 0.8408\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.5126 - accuracy: 0.8408\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4394 - accuracy: 0.8408\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4216 - accuracy: 0.8408\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4127 - accuracy: 0.8408\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4056 - accuracy: 0.8408\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.3989 - accuracy: 0.8408\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.3922 - accuracy: 0.8408\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.3855 - accuracy: 0.8408\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.3786 - accuracy: 0.8408\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.3716 - accuracy: 0.8408\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.3645 - accuracy: 0.8408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      " - 1s - loss: 0.3572 - accuracy: 0.8408\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.3499 - accuracy: 0.8408\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.3425 - accuracy: 0.8408\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.3351 - accuracy: 0.8408\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.3276 - accuracy: 0.8408\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.3202 - accuracy: 0.8408\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.3129 - accuracy: 0.8408\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.3057 - accuracy: 0.8408\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.2985 - accuracy: 0.8408\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.4635 - accuracy: 0.8408\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4361 - accuracy: 0.8408\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4258 - accuracy: 0.8408\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4189 - accuracy: 0.8408\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4128 - accuracy: 0.8408\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4068 - accuracy: 0.8408\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4008 - accuracy: 0.8408\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.3947 - accuracy: 0.8408\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.3884 - accuracy: 0.8408\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.3819 - accuracy: 0.8408\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.3753 - accuracy: 0.8408\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.3685 - accuracy: 0.8408\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.3615 - accuracy: 0.8408\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.3545 - accuracy: 0.8408\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.3473 - accuracy: 0.8408\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.3400 - accuracy: 0.8408\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.3327 - accuracy: 0.8408\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.3255 - accuracy: 0.8408\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.3182 - accuracy: 0.8408\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.3110 - accuracy: 0.8408\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.6679 - accuracy: 0.5990\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4725 - accuracy: 0.8408\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.4442 - accuracy: 0.8408\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.4365 - accuracy: 0.8408\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4325 - accuracy: 0.8408\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4293 - accuracy: 0.8408\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4264 - accuracy: 0.8408\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.4234 - accuracy: 0.8408\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.4205 - accuracy: 0.8408\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.4174 - accuracy: 0.8408\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.4143 - accuracy: 0.8408\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.4111 - accuracy: 0.8408\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.4077 - accuracy: 0.8408\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.4043 - accuracy: 0.8408\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.4006 - accuracy: 0.8408\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.3969 - accuracy: 0.8408\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.3929 - accuracy: 0.8408\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.3888 - accuracy: 0.8408\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.3845 - accuracy: 0.8408\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.3799 - accuracy: 0.8408\n",
      "76413/76413 [==============================] - 0s 1us/step\n",
      "The mean is:  0.840838760137558\n",
      "The standard deviation is:  3.185504425530426e-06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "input_shape = Xtrain.shape[1:]\n",
    "n_layers = 2\n",
    "n_nodes = 20\n",
    "\n",
    "# Define 10-fold cross validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle = True, random_state =1234)\n",
    "test_accuracy = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_shuffle, Y_shuffle):\n",
    "    Xtrain, Xtest = X_shuffle[train_index], X_shuffle[test_index]\n",
    "    Ytrain, Ytest = Y_shuffle[train_index], Y_shuffle[test_index]\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(Ytrain),Ytrain)\n",
    "    \n",
    "    model22 = build_DNN(input_shape, n_layers, n_nodes)\n",
    "    history22 = model22.fit(Xtrain, Ytrain, batch_size = batch_size, epochs = epochs, verbose = 2, class_weight = class_weights)\n",
    "    score = model22.evaluate(Xtest, Ytest, batch_size = batch_size)\n",
    "    test_accuracy.append(score[1])\n",
    "    \n",
    "print(\"The mean is: \", np.mean(test_accuracy))\n",
    "print(\"The standard deviation is: \", np.std(test_accuracy))\n",
    "# Loop over cross validation folds\n",
    "    \n",
    "    # Calculate class weights for current split\n",
    "    \n",
    "    # Rebuild the DNN model, to not continue training on the previously trained model\n",
    "    \n",
    "    # Fit the model with training set and class weights for this fold\n",
    "    \n",
    "    # Evaluate the model using the test set for this fold\n",
    "    \n",
    "    # Save the test accuracy in an array\n",
    "\n",
    "    \n",
    "# Calculate and print mean and std of accuracies\n",
    "\n",
    "#Answer 23: The mean is: 0.840838760137558\n",
    "#The standard deviation is:  3.185504425530426e-06\n",
    "\n",
    "#Answer 24: CV takes a very long time because you have to run the model 10 times (in this case), so Dropout is a lot quicker.\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 23: DNN regression\n",
    "\n",
    "A similar DNN can be used for regression, instead of classification.\n",
    "\n",
    "Question 25: How would you change the DNN in order to use it for regression instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to change the loss function to something like MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "\n",
    "Send in this jupyter notebook, with answers to all questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
